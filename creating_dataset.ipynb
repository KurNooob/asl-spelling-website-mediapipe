{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disabling TensorFlow OneDNN optimizations\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize MediaPipe Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Hands module and drawing utilities\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory path\n",
    "DATA_DIR = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Images and Extract Hand Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists for storing data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each subdirectory (representing classes) in the data directory\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    # Process each image file in the class directory\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []   # Auxiliary list to store normalized landmark points\n",
    "        x_ = []         # List to store x-coordinates of landmarks\n",
    "        y_ = []         # List to store y-coordinates of landmarks\n",
    "\n",
    "        # Load and convert image to RGB\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process image using MediaPipe Hands\n",
    "        results = hands.process(img_rgb)\n",
    "        \n",
    "        # Check if hand landmarks are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Extract normalized x and y coordinates of each landmark\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                # Normalize the coordinates by the minimum x and y\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            # Only append to data and labels if data_aux contains 42 elements\n",
    "            if len(data_aux) == 42:\n",
    "                data.append(data_aux)\n",
    "                labels.append(dir_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Processed Data to a Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and labels have been saved to 'data.pickle'\n"
     ]
    }
   ],
   "source": [
    "# Save data and labels as a pickle file\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump({'data': data, 'labels': labels}, f)\n",
    "print(\"Data and labels have been saved to 'data.pickle'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
